{"cells":[{"cell_type":"markdown","source":["\n","#**Data Cleaning and Preprocessing for NLP**\n","    - Cleantech Media Dataset (MAHA)\n","    -\n"],"metadata":{"id":"984YPNMVXnW2"}},{"cell_type":"markdown","source":["This notebook serves as a comprehensive guide to managing and analyzing media data related to clean technology. We will cover various data manipulation tasks including examining dataset dimensions, viewing sample data, and cleaning the dataset for further analysis.\n"],"metadata":{"id":"Gxwo3D4MaOo1"}},{"cell_type":"markdown","source":["## **Setting up the Environment**\n","\n","Before we begin any data analysis, we need to set up our working environment. This includes importing necessary libraries and ensuring our dataset is loaded correctly."],"metadata":{"id":"VysMImhbaKxA"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmIBv91F7hIm","executionInfo":{"status":"ok","timestamp":1713976264223,"user_tz":-120,"elapsed":9015,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"1a1da53c-83f7-4b11-cf74-0dd1100ddf11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"]}],"source":["# !pip install nltk\n","\n","import pandas as pd\n","import nltk\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/CLT/"],"metadata":{"id":"EQiutsMgXjGZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"tE4vxNIYYLDA"}},{"cell_type":"markdown","metadata":{"id":"ygFfp-zruw6o"},"source":[" ## **Import Libraries and Load Data**\n","\n"," After setting up the environment and navigating to the correct directory, lets load the datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X37ID-b5qd4X"},"outputs":[],"source":["# Paths to the datasets\n","cleantech_media_path = '/content/drive/My Drive/CLT/cleantech_media_dataset_v2_2024-02-23.csv'\n","\n","\n"," # Loading the datasets\n","cleantech_media_data = pd.read_csv(cleantech_media_path)"]},{"cell_type":"markdown","metadata":{"id":"BWYhK0BUvKC0"},"source":["## **Understanding the Dataset Structure**\n","\n","Display the Initial Shape of the Dataset\n","To get an understanding of the size and scope of our dataset, we first look at its shape, which tells us the number of rows and columns."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M22p3GK7qd7D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713976269135,"user_tz":-120,"elapsed":7,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"f13a9838-165d-4220-851f-e9de657f8709"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial Cleantech Media Data shape: (9593, 7)\n"]}],"source":["# Display the initial shape of the datasets\n","print(\"Initial Cleantech Media Data shape:\", cleantech_media_data.shape)"]},{"cell_type":"markdown","source":["This output informs us that the dataset contains 9,593 entries across 7 different columns. This indicates a robust dataset with multiple dimensions to analyze."],"metadata":{"id":"GOS8GqfVcD3B"}},{"cell_type":"markdown","source":["## **Data Inspection**\n","\n","To gain a thorough understanding of our dataset quickly, we can perform several inspections at once: viewing the first few entries, examining the column names, and checking the content of the first article. These steps are crucial for getting familiar with the dataset's structure and contents."],"metadata":{"id":"nHCpeWXVcb6I"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_FyL5rbqd9i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713976269136,"user_tz":-120,"elapsed":7,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"aa37ae2f-cd89-4683-ae65-9f305ab3912c"},"outputs":[{"output_type":"stream","name":"stdout","text":["   Unnamed: 0                                              title        date  \\\n","0        1280  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n","1        1281               India Launches Its First 700 MW PHWR  2021-01-15   \n","2        1283              New Chapter for US-China Energy Trade  2021-01-20   \n","3        1284  Japan: Slow Restarts Cast Doubt on 2030 Energy...  2021-01-22   \n","4        1285     NYC Pension Funds to Divest Fossil Fuel Shares  2021-01-25   \n","\n","  author                                            content       domain  \\\n","0    NaN  [\"Qatar Petroleum ( QP) is targeting aggressiv...  energyintel   \n","1    NaN  [\"â€¢ Nuclear Power Corp. of India Ltd. ( NPCIL)...  energyintel   \n","2    NaN  [\"New US President Joe Biden took office this ...  energyintel   \n","3    NaN  [\"The slow pace of Japanese reactor restarts c...  energyintel   \n","4    NaN  [\"Two of New York City's largest pension funds...  energyintel   \n","\n","                                                 url  \n","0  https://www.energyintel.com/0000017b-a7dc-de4c...  \n","1  https://www.energyintel.com/0000017b-a7dc-de4c...  \n","2  https://www.energyintel.com/0000017b-a7dc-de4c...  \n","3  https://www.energyintel.com/0000017b-a7dc-de4c...  \n","4  https://www.energyintel.com/0000017b-a7dc-de4c...  \n"]}],"source":["# Display the first few rows of the media dataset\n","print(cleantech_media_data.head())\n"]},{"cell_type":"markdown","source":["- The first few rows give us an immediate sense of the dataset, including the types of columns (e.g., title, date, content) and some entries that contain missing values (NaN) in the 'author' field.\n","- he 'content' field appears to be in a list format, suggesting that it might require cleaning or transformation before further analysis.\n","- Each row contains detailed information about different media articles, providing a rich source for analysis. The 'domain' column indicates the source of the information, and the 'url' provides a direct link to the original publication.\n","- The presence of NaN values in the 'author' column highlights a common issue in real-world data that will need to be addressed during data cleaning."],"metadata":{"id":"iqy9k9WPeklo"}},{"cell_type":"markdown","source":["## **Understanding Dataset Columns and Data Types**\n","\n","In this part of the analysis, we display the names of all columns to understand what data we have. We also check the content of the first row to get a sense of what kind of text data is stored in the 'content' column, and we verify the data types to ensure data consistency."],"metadata":{"id":"G6FRuXS_kBu3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NWE4sdZqeAJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713976269136,"user_tz":-120,"elapsed":5,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"a17fc234-90ba-493d-e79e-197b49c01724"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Unnamed: 0', 'title', 'date', 'author', 'content', 'domain', 'url'], dtype='object') \n","\n","[\"Qatar Petroleum ( QP) is targeting aggressive cuts in its greenhouse gas emissions as it prepares to launch Phase 2 of its planned 48 million ton per year LNG expansion. In its latest Sustainability Report published on Wednesday, QP said its goals include `` reducing the emissions intensity of Qatar's LNG facilities by 25% and of its upstream facilities by at least 15%. '' The company is also aiming to reduce gas flaring intensity across its upstream facilities by more than 75% and has raised its carbon capture and storage ambitions from 5 million tons/yr to 7 million tons/yr by 2027. About 2.2 million tons/yr of the carbon capture goal will come from the 32 million ton/yr Phase 1 of the LNG expansion, also known as the North Field East project. A further 1.1 million tons/yr will come from Phase 2, known as the North Field South project, which will raise Qatar's LNG capacity by a further 16 million tons/yr. Qatar currently has an LNG production capacity of around 78 million tons/yr and is eyeing a phased expansion to 126 million tons/yr. QP says it should be able to eliminate routine gas flaring by 2030, with methane emissions limited `` by setting a methane intensity target of 0.2% across all facilities by 2025. '' The company also plans to build some 1.6 gigawatts of solar energy capacity by 2025, half of which should come from the Siraj solar power project next year ( EIF Jan.22'20). Until this month, there had been little news about Phase 2 of Qatar's massive LNG expansion. But McDermott International said last week that it had been awarded the front-end engineering and design contract for five offshore wellhead platforms ( LNGI Jan.12'21). Bids for construction of all four trains for Phase 1 of the LNG expansion were submitted in September ( LNGI Sep.15'20). But QP judged them to be too expensive and none met its targeted 50-week construction schedule. Shortlisted contractors were asked to look for cost savings and submit new bids. The contract, which consultancy Rystad estimates to be worth around $ 35 billion, is expected to be awarded by Mar. 31. Shortly after the construction contract is awarded, QP is expected to select foreign investments partners to take stakes of up to 30% in the Phase 1 trains. Exxon Mobil, Royal Dutch Shell, Total, Chevron, ConocoPhillips and Eni have been shortlisted. QP has repeatedly said that it is prepared to proceed without international investment partners if it determines that the offers it receives are not sufficiently attractive. But the shortlisted companies are expected to bid aggressively for what is expected to be the world's lowest-cost and most environmentally friendly LNG ( LNGI Nov.9'20). Rafiq Latta, Nicosia\"] \n","\n","content\n","<class 'str'>    9593\n","Name: count, dtype: int64\n"]}],"source":["# Display the column names\n","print(cleantech_media_data.columns, \"\\n\")\n","\n","# Check the content of the first row\n","print(cleantech_media_data[\"content\"][0], \"\\n\")\n","\n","# Check the type of the content column\n","print(cleantech_media_data[\"content\"].apply(type).value_counts())"]},{"cell_type":"markdown","source":["- Column Names: The output lists all the columns in the dataset, including 'title', 'date', 'author', 'content', 'domain', and 'url'. This helps identify what kinds of information each column holds, which is essential for deciding how to handle each one during the analysis.\n","- First Row Content: The content of the first row provides insight into the detailed textual data stored in the 'content' column. It includes comprehensive information about corporate strategies and initiatives, which are critical for analyses related to business intelligence, policy making, or market trends.\n","- Data Type Verification: The data type of the 'content' column is confirmed to be <class 'str'>, indicating that all entries are stored as strings. This uniformity is crucial for text processing tasks, ensuring that methods like string manipulation or natural language processing can be applied directly without additional type conversion."],"metadata":{"id":"ifjLsDjCecym"}},{"cell_type":"markdown","source":["## **Data Cleaning Preparations: Identifying Missing Values and Duplicates**\n","\n","As part of our data cleaning process, it is crucial to first identify any missing values and duplicate entries. These steps are foundational for ensuring data quality and reliability for further analysis."],"metadata":{"id":"RlN9ADtOe6la"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wm2EbiSywqK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713976269136,"user_tz":-120,"elapsed":4,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"24ac7198-44d3-4236-ea1d-ea8c582dad32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values before cleaning:\n","Unnamed: 0       0\n","title            0\n","date             0\n","author        9562\n","content          0\n","domain           0\n","url              0\n","dtype: int64\n","Duplicates in media data: 0\n"]}],"source":["# Print missing values in each column\n","print(\"Missing values before cleaning:\")\n","print(cleantech_media_data.isnull().sum())\n","\n","# Check for duplicates in the media data\n","print(\"Duplicates in media data:\", cleantech_media_data.duplicated().sum())\n"]},{"cell_type":"markdown","source":["- Missing Values:\n","Unnamed: 0, title, date, content, domain, url: These columns have zero missing values, indicating that our dataset is consistently populated in most fields which are crucial for further analysis.\n","    - author: There are 9,562 missing values in the 'author' column, which is a significant number. This suggests that most of the entries in this dataset do not have an associated author. Depending on the goals of your analysis, you might choose to ignore this column if authorship is not relevant, or you may need to address these missing values, possibly by imputing data or by acknowledging this gap in any data-driven conclusions.\n","\n","- Duplicates:\n","The check for duplicates returned a count of zero, indicating that there are no duplicate rows within the dataset. This is an excellent sign as it means each entry is unique and will contribute individual insights to your analysis. I"],"metadata":{"id":"oSqU1xXWfIBL"}},{"cell_type":"markdown","metadata":{"id":"8gbrKrCFvXni"},"source":["## **Cleaning Text Data in the 'Content' Column**\n","Sometimes, data can be stored in formats that are not immediately usable for analysis, such as text stored as string representations of lists. Here, we'll convert these strings back into actual text, making them easier to work with for text analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qR5TInc-7hIu","executionInfo":{"status":"ok","timestamp":1713976270275,"user_tz":-120,"elapsed":1142,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"c71e920d-c914-47b1-af1d-32d8e710a6eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Qatar Petroleum ( QP) is targeting aggressive ...\n","1    â€¢ Nuclear Power Corp. of India Ltd. ( NPCIL) s...\n","2    New US President Joe Biden took office this we...\n","3    The slow pace of Japanese reactor restarts con...\n","4    Two of New York City's largest pension funds s...\n","Name: content, dtype: object"]},"metadata":{},"execution_count":8}],"source":["# Convert the string representation of list in 'content' column to actual list and then join as string\n","cleantech_media_data['content'] = cleantech_media_data['content'].apply(lambda x: ' '.join(ast.literal_eval(x)))\n","\n","# Show the cleaned 'content' column for the first few entries\n","cleantech_media_data['content'].head()"]},{"cell_type":"markdown","source":["Effective Conversion: The use of ast.literal_eval() successfully converted string representations of lists into actual list objects, which were then joined into coherent, continuous strings. This process ensured that each entry in the 'content' column is now in a straightforward text format, free from the complexities of list notations.\n","With the content now presented as clean, uninterrupted text, the dataset is more suitable for text analysis."],"metadata":{"id":"BGAsnmzDgd8q"}},{"cell_type":"markdown","source":["## **Advanced Data Cleaning**\n","As we progress with cleaning the dataset, it is essential to remove any unnecessary or redundant information, ensuring the data is as relevant and concise as possible for analysis."],"metadata":{"id":"bmQaIGoRgtUd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMT_pDt5vZoR"},"outputs":[],"source":["\n","# Drop rows with missing values in 'content' column\n","cleantech_media_data.dropna(subset=[\"content\"], inplace=True)\n","\n","# Remove duplicates\n","cleantech_media_data = cleantech_media_data.drop_duplicates()\n","\n","# Drop unnecessary 'Unnamed: 0' and 'author' columns\n","cleantech_media_data.drop(columns=['Unnamed: 0'], inplace=True)\n","cleantech_media_data.drop('author', axis=1, inplace=True)\n"]},{"cell_type":"markdown","source":["- Removing Missing Data: By removing rows with missing 'content', we ensure that our analysis is based only on complete data, improving the reliability of our results.\n","- Eliminating Duplicates: Removing duplicates helps in preventing any skew or bias that could affect the outcome of our analysis. It is essential for maintaining the datasetâ€™s integrity.\n","- Simplifying the Dataset: Dropping unnecessary columns helps focus the dataset on relevant data only. Removing the 'Unnamed: 0' column simplifies the DataFrame as this column is generally an artifact of the data loading process and does not contain useful information. Similarly, dropping the 'author' column, particularly because it contains a high number of missing values, reduces the complexity and potential noise within the dataset.\n","\n","These steps collectively enhance the quality of the dataset and prepare it for more effective data analysis, ensuring that the data is not only clean but also focused and relevant to the tasks at hand."],"metadata":{"id":"iXXxu-S8g6Ya"}},{"cell_type":"markdown","metadata":{"id":"WE6ej3arv6Xf"},"source":["## **Converting Date Columns to Datetime Format**\n","\n","Handling dates correctly in a dataset is crucial for many types of analysis, especially when time trends are involved. Converting date columns to a proper datetime format allows for more accurate and efficient operations on these data.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"enHUy1ytwCW2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713976270276,"user_tz":-120,"elapsed":10,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"1fac7974-edb9-45c1-f628-a1a447452bfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["title              object\n","date       datetime64[ns]\n","content            object\n","domain             object\n","url                object\n","dtype: object\n"]}],"source":["cleantech_media_data['date'] = pd.to_datetime(cleantech_media_data['date'])\n","print(cleantech_media_data.dtypes)\n"]},{"cell_type":"markdown","source":["- Datetime Conversion: The 'date' column has been successfully converted to datetime64[ns], the standard datetime format in pandas. This format will help in performing any date-time specific operations like sorting, filtering by date, time-series analysis, etc.\n","\n","- Data Types Verification: The data types output confirms that all other columns retain their original data type while the 'date' column is now appropriately formatted for any temporal analysis."],"metadata":{"id":"Q2OW5PDChV0z"}},{"cell_type":"markdown","source":["## **Final Verification of Data Structure and Types**\n","\n","After all our data cleaning and transformation steps, it is crucial to perform a final check on the data structure and types to ensure everything is in order and ready for analysis. This final verification helps confirm that the dataset is correctly formatted and that all changes have been properly implemented.\n","\n"],"metadata":{"id":"5suv32HXh_pV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"O9YlZsNVr3iO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713976270276,"user_tz":-120,"elapsed":6,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"7d5662e6-bc15-42a9-cf78-27764f10c32b"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9593 entries, 0 to 9592\n","Data columns (total 5 columns):\n"," #   Column   Non-Null Count  Dtype         \n","---  ------   --------------  -----         \n"," 0   title    9593 non-null   object        \n"," 1   date     9593 non-null   datetime64[ns]\n"," 2   content  9593 non-null   object        \n"," 3   domain   9593 non-null   object        \n"," 4   url      9593 non-null   object        \n","dtypes: datetime64[ns](1), object(4)\n","memory usage: 374.9+ KB\n","None\n"]}],"source":["# Final verification of data structure and types\n","print(cleantech_media_data.info())"]},{"cell_type":"markdown","source":["- The output confirms that the DataFrame has a total of 9,593 entries, matching the original dataset count, which means no data was lost unintentionally through the cleaning and transformation processes.\n","- Each column shows a 'Non-Null Count' equal to the total number of entries, indicating there are no missing values in these columns after our cleaning steps.\n","- The data types are correctly listed, with the 'date' column successfully converted to datetime64[ns] and other columns as object. This ensures that the data is formatted correctly for further analysis, particularly with the 'date' column now optimized for time-series and chronological analyses.\n","- The memory usage is listed, which provides insight into the dataset's size and can help in assessing computational resource needs for further data processing and analysis."],"metadata":{"id":"DTnwjiLwiMbN"}},{"cell_type":"markdown","metadata":{"id":"tJBYRLKdwGeV"},"source":["# **Text Preprocessing**\n","\n","## **Text Preprocessing Setup**\n","\n","Text preprocessing is a crucial step in any natural language processing (NLP) workflow. It involves setting up the necessary tools and transforming raw text into a clean and usable format. Here, we ensure that NLTK's tokenizers, stopwords, and lemmatizers are ready for text processing tasks.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z70NTrooszbH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713976274877,"user_tz":-120,"elapsed":2160,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"bbb617b7-974a-40b5-8469-a362ae15a7cb"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":13}],"source":["# Ensure that NLTK's tokenizers and stopwords data are available\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"markdown","source":["## **Defining a Text Preprocessing Function**\n","Properly preparing text data is crucial for most NLP tasks. This function is designed to standardize and simplify text, making it more amenable to analysis. The preprocessing steps include converting to lowercase, removing punctuation, tokenizing, removing stopwords, and lemmatizing."],"metadata":{"id":"TrzVyDfOk9Il"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyeYPiJDszkA"},"outputs":[],"source":["def preprocess_text(text):\n","    \"\"\"\n","    Function to preprocess text data by lowering case, removing punctuation,\n","    tokenizing, removing stopwords, and lemmatizing.\n","    \"\"\"\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Remove punctuation and special characters\n","    text = re.sub(r'[^a-z\\s]', '', text)\n","    # Tokenization\n","    tokens = nltk.word_tokenize(text)\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","    # Lemmatization\n","    lemmatizer = WordNetLemmatizer()\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","    return ' '.join(tokens)"]},{"cell_type":"markdown","source":["- Lowercasing is the first step in text preprocessing, used to treat words such as \"Hello,\" \"hello,\" the first step in text preprocessing, used to treat words such as \"Hello\", \"hello\", and \"HELLO\" as the same word.\n","- Removing Punctuation cleans the text, removing characters that could interfere with textual analysis (like punctuation and special characters), which aren't usually needed for understanding the meaning of text.\n","- Tokenization by breaking the text into individual elements (words), we can apply further processing like stopword removal and lemmatization.\n","- Stopwords are common words that typically don't contribute significantly to the meaning of a sentence (e.g., \"the\", \"is\", and \"at\"). Removing them helps focus on the important information.\n","- Lemmatization reduces words to their base or root form, helping to consolidate different forms of a word into a single item (e.g., \"running\", \"ran\", and \"runs\" become \"run\")."],"metadata":{"id":"H-9opqUdlGv7"}},{"cell_type":"markdown","source":["## **Applying Text Preprocessing to Dataset Columns**\n","After defining the text preprocessing function, it's crucial to apply this function to the relevant columns in our dataset. This ensures that the text data within these columns is clean and standardized, making it suitable for further analysis, such as feature extraction, sentiment analysis, or Text modeling."],"metadata":{"id":"-BP_-rz1lxaJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4pKGXeB7hIx","executionInfo":{"status":"ok","timestamp":1713976339307,"user_tz":-120,"elapsed":64435,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"9c52f022-a4e6-4eea-fefa-ee43fe65fd4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Media Data Preprocessed Sample:\n","                                               title  \\\n","0  Qatar to Slash Emissions as LNG Expansion Adva...   \n","1               India Launches Its First 700 MW PHWR   \n","2              New Chapter for US-China Energy Trade   \n","3  Japan: Slow Restarts Cast Doubt on 2030 Energy...   \n","4     NYC Pension Funds to Divest Fossil Fuel Shares   \n","\n","                           title_preprocessed  \\\n","0  qatar slash emission lng expansion advance   \n","1                  india launch first mw phwr   \n","2            new chapter uschina energy trade   \n","3  japan slow restarts cast doubt energy plan   \n","4   nyc pension fund divest fossil fuel share   \n","\n","                                             content  \\\n","0  Qatar Petroleum ( QP) is targeting aggressive ...   \n","1  â€¢ Nuclear Power Corp. of India Ltd. ( NPCIL) s...   \n","2  New US President Joe Biden took office this we...   \n","3  The slow pace of Japanese reactor restarts con...   \n","4  Two of New York City's largest pension funds s...   \n","\n","                                content_preprocessed  \n","0  qatar petroleum qp targeting aggressive cut gr...  \n","1  nuclear power corp india ltd npcil synchronize...  \n","2  new u president joe biden took office week usc...  \n","3  slow pace japanese reactor restarts continues ...  \n","4  two new york city largest pension fund say div...  \n"]}],"source":["# Preprocess 'title' and 'content' columns in the media dataset\n","cleantech_media_data['title_preprocessed'] = cleantech_media_data['title'].apply(preprocess_text)\n","cleantech_media_data['content_preprocessed'] = cleantech_media_data['content'].apply(preprocess_text)\n","\n","# Displaying a sample of the preprocessed data\n","print(\"Media Data Preprocessed Sample:\")\n","print(cleantech_media_data[['title', 'title_preprocessed', 'content', 'content_preprocessed']].head())"]},{"cell_type":"markdown","source":["The output shows both the original and preprocessed versions of the 'title' and 'content' columns. This allows for a clear comparison to see how the text has been simplified and standardized.\n","\n","- Titles: The preprocessing removes all non-alphabetic characters, lowercases the text, and removes stopwords. This simplifies the titles, focusing only on the key words.\n","- Content: Similar transformations are applied to the content, which now ignores irrelevant punctuation and common words, and normalizes the text for further analysis."],"metadata":{"id":"hNQWAIIjmCWJ"}},{"cell_type":"markdown","metadata":{"id":"4hiIoZo7wMjA"},"source":["## **Final Verification and Overview**\n","Before concluding our data preprocessing tasks, it's good practice to perform a final check to ensure all transformations have been applied correctly to the dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QqKUmlU1szm2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713976339307,"user_tz":-120,"elapsed":13,"user":{"displayName":"Maha Zayour","userId":"15216997039006806750"}},"outputId":"fe763070-2fe0-46dc-eff8-99697598d7da"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                               title       date  \\\n","0  Qatar to Slash Emissions as LNG Expansion Adva... 2021-01-13   \n","1               India Launches Its First 700 MW PHWR 2021-01-15   \n","2              New Chapter for US-China Energy Trade 2021-01-20   \n","3  Japan: Slow Restarts Cast Doubt on 2030 Energy... 2021-01-22   \n","4     NYC Pension Funds to Divest Fossil Fuel Shares 2021-01-25   \n","\n","                                             content       domain  \\\n","0  Qatar Petroleum ( QP) is targeting aggressive ...  energyintel   \n","1  â€¢ Nuclear Power Corp. of India Ltd. ( NPCIL) s...  energyintel   \n","2  New US President Joe Biden took office this we...  energyintel   \n","3  The slow pace of Japanese reactor restarts con...  energyintel   \n","4  Two of New York City's largest pension funds s...  energyintel   \n","\n","                                                 url  \\\n","0  https://www.energyintel.com/0000017b-a7dc-de4c...   \n","1  https://www.energyintel.com/0000017b-a7dc-de4c...   \n","2  https://www.energyintel.com/0000017b-a7dc-de4c...   \n","3  https://www.energyintel.com/0000017b-a7dc-de4c...   \n","4  https://www.energyintel.com/0000017b-a7dc-de4c...   \n","\n","                           title_preprocessed  \\\n","0  qatar slash emission lng expansion advance   \n","1                  india launch first mw phwr   \n","2            new chapter uschina energy trade   \n","3  japan slow restarts cast doubt energy plan   \n","4   nyc pension fund divest fossil fuel share   \n","\n","                                content_preprocessed  \n","0  qatar petroleum qp targeting aggressive cut gr...  \n","1  nuclear power corp india ltd npcil synchronize...  \n","2  new u president joe biden took office week usc...  \n","3  slow pace japanese reactor restarts continues ...  \n","4  two new york city largest pension fund say div...  \n"]}],"source":["print(cleantech_media_data.head())\n"]},{"cell_type":"markdown","source":["The first few rows show the preprocessed 'title' and 'content' along with the original columns, confirming that our data transformations have been applied throughout the dataset."],"metadata":{"id":"iNbmRLPvmo4c"}},{"cell_type":"markdown","source":["## **Saving the Preprocessed Data**\n","After verifying that the data is clean and correctly formatted, it is crucial to save the processed data to a file for future use or further analysis.\n","\n"],"metadata":{"id":"yJqMmFjrmgrG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fgRUkpu7hIx"},"outputs":[],"source":["# Path to the NLP folder on your desktop\n","\n","# Path to the NLP folder on your desktop\n","path_to_save = '/content/drive/My Drive/CLT/cleantech_media_dataset_cleaned.csv'\n","\n","# Save the DataFrame to CSV\n","cleantech_media_data.to_csv(path_to_save, index=False)\n"]},{"cell_type":"markdown","source":["By saving the DataFrame to a CSV file, we ensure that all the preprocessing steps are preserved. This file can now be used for further analysis, machine learning models, or reporting without needing to reapply preprocessing steps."],"metadata":{"id":"0qlP7SKSmv3s"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}